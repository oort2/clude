#####################
#RNN(Recurrent Neural Network) : 순환신경망
#   음성인식, 문장번역 등에 사용
#####################

'''

#SimpleRNN
#return_sequences=True
#activation = 'tanh' : -1~1 사이의 값을 가짐
rnn1 = SimpleRNN(units=1, activation='tanh', return_sequences=True)
X=[] #[[0.0], [0.1], [0.2], [0.3]] ...
Y=[] #[0.4, 0.5]

for i in range(6) :  #0~5
    #list = [0.1,0.2,0.3,0.4]
    lst = list(range(i, i+4)) #0~3
    X.append(list(map(lambda c : [c/10], lst)))
    Y.append((i+4)/10)

X=np.array(X) #배열로 변경
Y=np.array(Y)
 
for i in range(len(X)) :
    #np.squeeze : X[i] -> 1차원 배열로 변경
    print(np.squeeze(X[i]),Y[i])
X.shape

import tensorflow as tf
model = tf.keras.Sequential([
    SimpleRNN(units=10, return_sequences=False, input_shape=[4,1]),
    Dense(1)
    ])
#mse: 평균제곱오차
model.compile(optimizer='adam', loss='mse')
model.summary()
X
model.fit(X,Y,epochs=1000, verbose=0)
print(model.predict(X)) #학습데이터예측

#학습되지 않은 데이터
print(model.predict(np.array([[0.6],[0.7],[0.8],[0.9]])))
print(model.predict(np.array([[-0.1],[0.0],[0.1],[0.2]])))
#예측못함
print(model.predict(np.array([[[1],[2],[3],[4]]])))




#########################################
#단어분석  _ RNN 단어분석에서 제일 중요한건 토큰화 
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import to_categorical

texts = ['You are the Best Thing', 'You are the Nice']
#Tokenizer: 토큰화 객체
#num_words = 10:10개의 토큰으로 분리.
#oov_token ='<OOV>' : 분석된 토큰에 없는 단어의 경우 대체되는 문자열
tokenizer = Tokenizer(num_words=10, oov_token='<OOV>')

#texts 내용을 토큰화.
tokenizer.fit_on_texts(texts)





#texts_to_sequences: texts 데이터와 토큰인덱스를 매칭
sequences = tokenizer.texts_to_sequences(texts)
#sequences_to_matrix: texts 데이터를 토큰 인덱스의 위치값을 1로 설정
binary_results = tokenizer.sequences_to_matrix(sequences, mode='binary')
texts
print(tokenizer.word_index)
print(sequences)
print(binary_results)


test_text = ['You are the One']
test_seq = tokenizer.texts_to_sequences(test_text)
print(test_seq)
#test_text 데이터를 이진매핑으로 출력하기
test_bin = tokenizer.sequences_to_matrix(test_seq, mode="binary")
test_bin
